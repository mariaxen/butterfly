{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import *    \n",
    "import os \n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import butterfly.album\n",
    "import butterfly.Models\n",
    "from itertools import combinations \n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from random import sample\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from collections import defaultdict\n",
    "from cython.parallel import prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5 #features to sample from each dataset\n",
    "\n",
    "#Model\n",
    "nruns = 1 #number of runs\n",
    "folds = 10 #number of folds\n",
    "features = 1 #number of features to predict\n",
    "epochs = 180 #number of epochs\n",
    "optimiser = 'adam' #model optimiser\n",
    "loss = 'mse' #model loss\n",
    "ntrees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import your data\n",
    "#DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = DF['patientID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the predictor datasets\n",
    "omics = ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/src/butterfly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums_all.pkl', 'rb') as f:\n",
    "    albums_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF_predictor.pkl', 'rb') as f:\n",
    "    RF_predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums.pkl', 'rb') as f:\n",
    "    albums = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 1/7 [30:15<3:01:32, 1815.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▊       | 2/7 [2:06:19<4:09:59, 2999.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 3/7 [4:50:40<5:37:12, 5058.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#Initialise lists\n",
    "fCNN = defaultdict(list)\n",
    "fRF = defaultdict(list)\n",
    "fMCNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "    \n",
    "    CNN = defaultdict(list)\n",
    "    RF = defaultdict(list)\n",
    "    MCNN = defaultdict(list)\n",
    "\n",
    "    #Get your response dataset\n",
    "    DFB = DF.copy()\n",
    "    response = sample([col for col in DFB if col.startswith(omics[predictor_index])], n_samples)\n",
    "    response_df = DFB[response]\n",
    "    \n",
    "    y = response_df.values\n",
    "    \n",
    "    #Get your predictor dataset\n",
    "\n",
    "    #CNN\n",
    "    X_CNN = np.asarray(albums_all[predictor_index])\n",
    "    \n",
    "    #Multi-layered CNN \n",
    "    X_MCNN = [albums[0], albums[1], albums[2], albums[3], albums[4], albums[5], albums[6]]\n",
    "    del X_MCNN[predictor_index]\n",
    "    X_MCNN = np.array(X_MCNN, dtype = float)\n",
    "    \n",
    "    #RF\n",
    "    #Get your predictor dataset\n",
    "    X_RF = RF_predictor[predictor_index]\n",
    "    X_RF = X_RF.values\n",
    "    X_RF = StandardScaler().fit_transform(X_RF)\n",
    "    \n",
    "    for feat in prange(y.shape[1], nogil=True):\n",
    "\n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                               (delayed(butterfly.Models.CNN)\n",
    "                                (X_CNN, y[:,feat], groups, 128, features, \n",
    "                                 folds, epochs, optimiser, loss, 'CNN') \n",
    "                                for cv in range(nruns)))                \n",
    "\n",
    "        CNN['prediction_train'].append(prediction_train)\n",
    "        CNN['observed_train'].append(observed_train)\n",
    "        CNN['prediction_test'].append(prediction_test)\n",
    "        CNN['observed_test'].append(observed_test)\n",
    "        \n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                               (delayed(butterfly.Models.RF)\n",
    "                                (X_RF, y[:,feat], groups, folds, ntrees, 'RF_regressor') \n",
    "                                for cv in range(nruns)))                \n",
    "\n",
    "        RF['prediction_train'].append(prediction_train)\n",
    "        RF['observed_train'].append(observed_train)\n",
    "        RF['prediction_test'].append(prediction_test)\n",
    "        RF['observed_test'].append(observed_test)\n",
    "        \n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                                (delayed(butterfly.Models.CNN)\n",
    "                        (X_MCNN, y[:,feat], groups, 40, features, \n",
    "                         folds, epochs, optimiser, loss, 'MCNN') \n",
    "                        for cv in range(nruns)))\n",
    "        \n",
    "        MCNN['prediction_train'].append(prediction_train)\n",
    "        MCNN['observed_train'].append(observed_train)\n",
    "        MCNN['prediction_test'].append(prediction_test)\n",
    "        MCNN['observed_test'].append(observed_test)\n",
    "\n",
    "\n",
    "    fCNN['prediction_train'].append(CNN['prediction_train'])\n",
    "    fCNN['observed_train'].append(CNN['observed_train'])\n",
    "    fCNN['prediction_test'].append(CNN['prediction_test'])\n",
    "    fCNN['observed_test'].append(CNN['observed_test'])\n",
    "    \n",
    "    fRF['prediction_train'].append(RF['prediction_train'])\n",
    "    fRF['observed_train'].append(RF['observed_train'])\n",
    "    fRF['prediction_test'].append(RF['prediction_test'])\n",
    "    fRF['observed_test'].append(RF['observed_test'])\n",
    "    \n",
    "    fMCNN['prediction_train'].append(MCNN['prediction_train'])\n",
    "    fMCNN['observed_train'].append(MCNN['observed_train'])\n",
    "    fMCNN['prediction_test'].append(MCNN['prediction_test'])\n",
    "    fMCNN['observed_test'].append(MCNN['observed_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_omic_CNN = []\n",
    "for l in range(len(omics)):\n",
    "    each_feature_CNN = []\n",
    "    for k in range(n_samples):\n",
    "        each_run_CNN = []\n",
    "        for i in range(nruns):\n",
    "            each_run_CNN.append(stats.spearmanr(fCNN['prediction_test'][l][k][i], \n",
    "                                                          fCNN['observed_test'][l][k][i]))\n",
    "        each_feature_CNN.append(np.mean(each_run_CNN))\n",
    "    each_omic_CNN.append(np.mean(each_feature_CNN))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_omic_RF = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_RF = []\n",
    "    for k in range(n_samples):\n",
    "        each_run_RF = []\n",
    "        for i in range(nruns):\n",
    "            each_run_RF.append(stats.spearmanr(fRF['prediction_test'][l][k][i], \n",
    "                                                          fRF['observed_test'][l][k][i]))\n",
    "        each_feature_RF.append(np.mean(each_run_RF))\n",
    "    each_omic_RF.append(np.mean(each_feature_RF))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_omic_MCNN = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_MCNN = []\n",
    "    for k in range(n_samples):\n",
    "        each_run_MCNN = []\n",
    "        for i in range(nruns):\n",
    "            each_run_MCNN.append(stats.spearmanr(fMCNN['prediction_test'][l][k][i], \n",
    "                                                          fMCNN['observed_test'][l][k][i]))\n",
    "        each_feature_MCNN.append(np.mean(each_run_MCNN))\n",
    "    each_omic_MCNN.append(np.mean(each_feature_MCNN))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08011759541851689"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16343609903575282"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21882940586129962"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_MCNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}