{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import *    \n",
    "import os \n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import butterfly.album\n",
    "import butterfly.Models\n",
    "from itertools import combinations \n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from random import sample\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20 #features to sample from each dataset\n",
    "\n",
    "#Model\n",
    "nruns = 5 #number of runs\n",
    "folds = 10 #number of folds\n",
    "features = 1 #number of features to predict\n",
    "epochs = 180 #number of epochs\n",
    "optimiser = 'adam' #model optimiser\n",
    "loss = 'mse' #model loss\n",
    "ntrees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import your data\n",
    "#DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = DF['patientID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the predictor datasets\n",
    "omics = ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/src/butterfly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums_all.pkl', 'rb') as f:\n",
    "    albums_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF_predictor.pkl', 'rb') as f:\n",
    "    RF_predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums.pkl', 'rb') as f:\n",
    "    albums = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#Initialise lists\n",
    "fCNN = defaultdict(list)\n",
    "fRF = defaultdict(list)\n",
    "fMCNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "    \n",
    "    CNN = defaultdict(list)\n",
    "    RF = defaultdict(list)\n",
    "    MCNN = defaultdict(list)\n",
    "\n",
    "    #Get your response dataset\n",
    "    DFB = DF.copy()\n",
    "    response = sample([col for col in DFB if col.startswith(omics[predictor_index])], n_samples)\n",
    "    response_df = DFB[response]\n",
    "    \n",
    "    y = response_df.values\n",
    "    \n",
    "    #Get your predictor dataset\n",
    "\n",
    "    #CNN\n",
    "    X_CNN = np.asarray(albums_all[predictor_index])\n",
    "    \n",
    "    #Multi-layered CNN \n",
    "    X_MCNN = [albums[0], albums[1], albums[2], albums[3], albums[4], albums[5], albums[6]]\n",
    "    del X_MCNN[predictor_index]\n",
    "    X_MCNN = np.array(X_MCNN, dtype = float)\n",
    "    \n",
    "    #RF\n",
    "    #Get your predictor dataset\n",
    "    X_RF = RF_predictor[predictor_index]\n",
    "    X_RF = X_RF.values\n",
    "    X_RF = StandardScaler().fit_transform(X_RF)\n",
    "    \n",
    "    for feat in tqdm(range(y.shape[1])):\n",
    "\n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                               (delayed(butterfly.Models.CNN)\n",
    "                                (X_CNN, y[:,feat], groups, 128, features, \n",
    "                                 folds, epochs, optimiser, loss, 'CNN') \n",
    "                                for cv in range(nruns)))                \n",
    "\n",
    "        CNN['prediction_train'].append(prediction_train)\n",
    "        CNN['observed_train'].append(observed_train)\n",
    "        CNN['prediction_test'].append(prediction_test)\n",
    "        CNN['observed_test'].append(observed_test)\n",
    "        \n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                               (delayed(butterfly.Models.RF)\n",
    "                                (X_RF, y[:,feat], groups, folds, ntrees, 'RF_regressor') \n",
    "                                for cv in range(nruns)))                \n",
    "\n",
    "        RF['prediction_train'].append(prediction_train)\n",
    "        RF['observed_train'].append(observed_train)\n",
    "        RF['prediction_test'].append(prediction_test)\n",
    "        RF['observed_test'].append(observed_test)\n",
    "        \n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                                (delayed(butterfly.Models.CNN)\n",
    "                        (X_MCNN, y[:,feat], groups, 40, features, \n",
    "                         folds, epochs, optimiser, loss, 'MCNN') \n",
    "                        for cv in range(nruns)))\n",
    "        \n",
    "        MCNN['prediction_train'].append(prediction_train)\n",
    "        MCNN['observed_train'].append(observed_train)\n",
    "        MCNN['prediction_test'].append(prediction_test)\n",
    "        MCNN['observed_test'].append(observed_test)\n",
    "\n",
    "\n",
    "    fCNN['prediction_train'].append(CNN['prediction_train'])\n",
    "    fCNN['observed_train'].append(CNN['observed_train'])\n",
    "    fCNN['prediction_test'].append(CNN['prediction_test'])\n",
    "    fCNN['observed_test'].append(CNN['observed_test'])\n",
    "    \n",
    "    fRF['prediction_train'].append(RF['prediction_train'])\n",
    "    fRF['observed_train'].append(RF['observed_train'])\n",
    "    fRF['prediction_test'].append(RF['prediction_test'])\n",
    "    fRF['observed_test'].append(RF['observed_test'])\n",
    "    \n",
    "    fMCNN['prediction_train'].append(MCNN['prediction_train'])\n",
    "    fMCNN['observed_train'].append(MCNN['observed_train'])\n",
    "    fMCNN['prediction_test'].append(MCNN['prediction_test'])\n",
    "    fMCNN['observed_test'].append(MCNN['observed_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_run_CNN = []\n",
    "each_feature_CNN = []\n",
    "each_omic_CNN = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    for k in range(n_samples):\n",
    "        for i in range(nruns):\n",
    "            each_run_CNN.append(stats.spearmanr(fCNN['prediction_test'][l][k][i], \n",
    "                                                          fCNN['observed_test'][l][k][i]))\n",
    "        each_feature_CNN.append(np.mean(each_run_CNN))\n",
    "    each_omic_CNN.append(np.mean(each_feature_CNN))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_run_RF = []\n",
    "each_feature_RF = []\n",
    "each_omic_RF = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    for k in range(n_samples):\n",
    "        for i in range(nruns):\n",
    "            each_run_RF.append(stats.spearmanr(fRF['prediction_test'][l][k][i], \n",
    "                                                          fRF['observed_test'][l][k][i]))\n",
    "        each_feature_RF.append(np.mean(each_run_RF))\n",
    "    each_omic_RF.append(np.mean(each_feature_RF))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_run_MCNN = []\n",
    "each_feature_MCNN = []\n",
    "each_omic_MCNN = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    for k in range(n_samples):\n",
    "        for i in range(nruns):\n",
    "            each_run_MCNN.append(stats.spearmanr(fMCNN['prediction_test'][l][k][i], \n",
    "                                                          fMCNN['observed_test'][l][k][i]))\n",
    "        each_feature_MCNN.append(np.mean(each_run_MCNN))\n",
    "    each_omic_MCNN.append(np.mean(each_feature_MCNN))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.27246523343115525,\n",
       " -0.13871890965769823,\n",
       " -0.0749296326761706,\n",
       " -0.03700000881903534,\n",
       " -0.02425015091351835,\n",
       " -0.012268433270861226,\n",
       " -0.0011907991611791002]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_omic_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14645208360409526,\n",
       " 0.18894757610867657,\n",
       " 0.18899957421811853,\n",
       " 0.17225460442875454,\n",
       " 0.154844291965741,\n",
       " 0.14651336814320937,\n",
       " 0.14604119478167438]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_omic_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2261168619844765,\n",
       " 0.22849711389511718,\n",
       " 0.23798837887205684,\n",
       " 0.2149482833306608,\n",
       " 0.20889952499526268,\n",
       " 0.20987527407293394,\n",
       " 0.20548040387858943]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_omic_MCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08011759541851689"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16343609903575282"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21882940586129962"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_MCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}