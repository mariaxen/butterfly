{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import *    \n",
    "import os \n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import butterfly.album\n",
    "import butterfly.Models\n",
    "from itertools import combinations \n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from random import sample\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1 #features to sample from each dataset\n",
    "\n",
    "#Model\n",
    "nruns = 1 #number of runs\n",
    "folds = 10 #number of folds\n",
    "features = 1 #number of features to predict\n",
    "epochs = 180 #number of epochs\n",
    "optimiser = 'adam' #model optimiser\n",
    "loss = 'mse' #model loss\n",
    "ntrees = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import your data\n",
    "#DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = DF['patientID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the predictor datasets\n",
    "omics = ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/src/butterfly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums_all.pkl', 'rb') as f:\n",
    "    albums_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF_predictor.pkl', 'rb') as f:\n",
    "    RF_predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums.pkl', 'rb') as f:\n",
    "    albums = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#Initialise lists\n",
    "fCNN = defaultdict(list)\n",
    "fRF = defaultdict(list)\n",
    "fMCNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "    \n",
    "    CNN = defaultdict(list)\n",
    "    RF = defaultdict(list)\n",
    "    MCNN = defaultdict(list)\n",
    "\n",
    "    #Get your response dataset\n",
    "    DFB = DF.copy()\n",
    "    response = sample([col for col in DFB if col.startswith(omics[predictor_index])], n_samples)\n",
    "    response_df = DFB[response]\n",
    "    \n",
    "    y = response_df.values\n",
    "    \n",
    "    #Get your predictor dataset\n",
    "\n",
    "    #CNN\n",
    "    X_CNN = np.asarray(albums_all[predictor_index])\n",
    "    \n",
    "    #Multi-layered CNN \n",
    "    X_MCNN = [albums[0], albums[1], albums[2], albums[3], albums[4], albums[5], albums[6]]\n",
    "    del X_MCNN[predictor_index]\n",
    "    X_MCNN = np.array(X_MCNN, dtype = float)\n",
    "    \n",
    "    #RF\n",
    "    #Get your predictor dataset\n",
    "    X_RF = RF_predictor[predictor_index]\n",
    "    X_RF = X_RF.values\n",
    "    X_RF = StandardScaler().fit_transform(X_RF)\n",
    "    \n",
    "    for feat in tqdm(range(y.shape[1])):\n",
    "\n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                               (delayed(butterfly.Models.CNN)\n",
    "                                (X_CNN, y[:,feat], groups, 128, features, \n",
    "                                 folds, epochs, optimiser, loss, 'CNN') \n",
    "                                for cv in range(nruns)))                \n",
    "\n",
    "        CNN['prediction_train'].append(prediction_train)\n",
    "        CNN['observed_train'].append(observed_train)\n",
    "        CNN['prediction_test'].append(prediction_test)\n",
    "        CNN['observed_test'].append(observed_test)\n",
    "        \n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                               (delayed(butterfly.Models.RF)\n",
    "                                (X_RF, y[:,feat], groups, folds, ntrees, 'RF_regressor') \n",
    "                                for cv in range(nruns)))                \n",
    "\n",
    "        RF['prediction_train'].append(prediction_train)\n",
    "        RF['observed_train'].append(observed_train)\n",
    "        RF['prediction_test'].append(prediction_test)\n",
    "        RF['observed_test'].append(observed_test)\n",
    "        \n",
    "        prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=nruns)\n",
    "                                (delayed(butterfly.Models.CNN)\n",
    "                        (X_MCNN, y[:,feat], groups, 40, features, \n",
    "                         folds, epochs, optimiser, loss, 'MCNN') \n",
    "                        for cv in range(nruns)))\n",
    "        \n",
    "        MCNN['prediction_train'].append(prediction_train)\n",
    "        MCNN['observed_train'].append(observed_train)\n",
    "        MCNN['prediction_test'].append(prediction_test)\n",
    "        MCNN['observed_test'].append(observed_test)\n",
    "\n",
    "\n",
    "    fCNN['prediction_train'].append(CNN['prediction_train'])\n",
    "    fCNN['observed_train'].append(CNN['observed_train'])\n",
    "    fCNN['prediction_test'].append(CNN['prediction_test'])\n",
    "    fCNN['observed_test'].append(CNN['observed_test'])\n",
    "    \n",
    "    fRF['prediction_train'].append(RF['prediction_train'])\n",
    "    fRF['observed_train'].append(RF['observed_train'])\n",
    "    fRF['prediction_test'].append(RF['prediction_test'])\n",
    "    fRF['observed_test'].append(RF['observed_test'])\n",
    "    \n",
    "    fMCNN['prediction_train'].append(MCNN['prediction_train'])\n",
    "    fMCNN['observed_train'].append(MCNN['observed_train'])\n",
    "    fMCNN['prediction_test'].append(MCNN['prediction_test'])\n",
    "    fMCNN['observed_test'].append(MCNN['observed_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fCNN['prediction_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_run_CNN = []\n",
    "each_feature_CNN = []\n",
    "each_omic_CNN = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    for k in range(n_samples):\n",
    "        for i in range(nruns):\n",
    "            each_run_CNN.append(stats.spearmanr(fCNN['prediction_test'][l][k][i], \n",
    "                                                          fCNN['observed_test'][l][k][i]))\n",
    "        each_feature_CNN.append(np.mean(each_run_CNN))\n",
    "    each_omic_CNN.append(np.mean(each_feature_CNN))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_run_RF = []\n",
    "each_feature_RF = []\n",
    "each_omic_RF = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    for k in range(n_samples):\n",
    "        for i in range(nruns):\n",
    "            each_run_RF.append(stats.spearmanr(fRF['prediction_test'][l][k][i], \n",
    "                                                          fRF['observed_test'][l][k][i]))\n",
    "        each_feature_RF.append(np.mean(each_run_RF))\n",
    "    each_omic_RF.append(np.mean(each_feature_RF))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_run_MCNN = []\n",
    "each_feature_MCNN = []\n",
    "each_omic_MCNN = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    for k in range(n_samples):\n",
    "        for i in range(nruns):\n",
    "            each_run_MCNN.append(stats.spearmanr(fMCNN['prediction_test'][l][k][i], \n",
    "                                                          fMCNN['observed_test'][l][k][i]))\n",
    "        each_feature_MCNN.append(np.mean(each_run_MCNN))\n",
    "    each_omic_MCNN.append(np.mean(each_feature_MCNN))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=0.15444295902328328, pvalue=0.20856602777135644),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158),\n",
       " SpearmanrResult(correlation=-0.2182999731366469, pvalue=0.0737097841380158)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_run_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1912053104157273,\n",
       " 0.2025406283958502,\n",
       " 0.20783044345324087,\n",
       " 0.21096115032394147,\n",
       " 0.21305548526503088,\n",
       " 0.21456620672050583,\n",
       " 0.21571323743833332]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_omic_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_MCNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(each_omic_RF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(each_omic_CNN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.mean(each_omic_MCNN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3580683702772727,\n",
       " 0.34918105119189746,\n",
       " 0.3450336356187224,\n",
       " 0.3425790427284759,\n",
       " 0.3409370047260351,\n",
       " 0.3397525418245557,\n",
       " 0.3388532262510592]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0867522754583725"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20798178028751854"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.344914981802574"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(each_omic_MCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}