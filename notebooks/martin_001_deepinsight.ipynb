{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# disable parallelization for BLAS and co.\n",
    "from nalabtools.utils.parallelization import set_threads_for_external_libraries\n",
    "set_threads_for_external_libraries(n_threads=1)\n",
    "\n",
    "# general\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ml / stats\n",
    "import sklearn as sk\n",
    "import statsmodels.stats.multitest\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nalab\n",
    "import nalabtools\n",
    "\n",
    "# init notebook files\n",
    "import nalabtools.utils.misc\n",
    "nbfile = nalabtools.utils.misc.init_notebook_file(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "file = h5py.File('../data/deepinsight/dataset2.mat', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = file[\"dset\"][\"Xtrain\"][...]\n",
    "X_test_raw = file[\"dset\"][\"Xtest\"][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.repeat([0,1], file[\"dset\"][\"num_tr\"][...].flatten().astype(np.int))\n",
    "y_test = np.repeat([0,1], file[\"dset\"][\"num_tst\"][...].flatten().astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6660, 20) (6660,) (740, 20) (740,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = sklearn.preprocessing.MinMaxScaler().fit(X_train_raw)\n",
    "X_train = preprocessing.transform(X_train_raw)\n",
    "X_test = preprocessing.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive images and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import butterfly.deepinsight.album2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = butterfly.deepinsight.album2.AlbumTransformer(40)\n",
    "at.fit(X_train)\n",
    "X_train_album = at.transform_parallel(X_train, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_album = at.transform_parallel(X_test, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "dataset_train = butterfly.deepinsight.album2.AlbumDataset(X_train_album[:,1,:,:], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import butterfly.deepinsight.deepinsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    30] loss: 0.701\n",
      "[1,    60] loss: 0.698\n",
      "[1,    90] loss: 0.697\n",
      "[2,    30] loss: 0.696\n",
      "[2,    60] loss: 0.694\n",
      "[2,    90] loss: 0.696\n",
      "[3,    30] loss: 0.693\n",
      "[3,    60] loss: 0.692\n",
      "[3,    90] loss: 0.690\n",
      "[4,    30] loss: 0.690\n",
      "[4,    60] loss: 0.690\n",
      "[4,    90] loss: 0.687\n",
      "[5,    30] loss: 0.686\n",
      "[5,    60] loss: 0.685\n",
      "[5,    90] loss: 0.687\n",
      "[6,    30] loss: 0.682\n",
      "[6,    60] loss: 0.683\n",
      "[6,    90] loss: 0.683\n",
      "[7,    30] loss: 0.679\n",
      "[7,    60] loss: 0.682\n",
      "[7,    90] loss: 0.680\n",
      "[8,    30] loss: 0.678\n",
      "[8,    60] loss: 0.677\n",
      "[8,    90] loss: 0.678\n",
      "[9,    30] loss: 0.675\n",
      "[9,    60] loss: 0.676\n",
      "[9,    90] loss: 0.673\n",
      "[10,    30] loss: 0.672\n",
      "[10,    60] loss: 0.674\n",
      "[10,    90] loss: 0.670\n",
      "[11,    30] loss: 0.670\n",
      "[11,    60] loss: 0.669\n",
      "[11,    90] loss: 0.669\n",
      "[12,    30] loss: 0.667\n",
      "[12,    60] loss: 0.666\n",
      "[12,    90] loss: 0.667\n",
      "[13,    30] loss: 0.664\n",
      "[13,    60] loss: 0.665\n",
      "[13,    90] loss: 0.665\n",
      "[14,    30] loss: 0.662\n",
      "[14,    60] loss: 0.661\n",
      "[14,    90] loss: 0.663\n",
      "[15,    30] loss: 0.660\n",
      "[15,    60] loss: 0.662\n",
      "[15,    90] loss: 0.657\n",
      "[16,    30] loss: 0.658\n",
      "[16,    60] loss: 0.657\n",
      "[16,    90] loss: 0.657\n",
      "[17,    30] loss: 0.655\n",
      "[17,    60] loss: 0.656\n",
      "[17,    90] loss: 0.655\n",
      "[18,    30] loss: 0.654\n",
      "[18,    60] loss: 0.653\n",
      "[18,    90] loss: 0.653\n",
      "[19,    30] loss: 0.651\n",
      "[19,    60] loss: 0.652\n",
      "[19,    90] loss: 0.650\n",
      "[20,    30] loss: 0.651\n",
      "[20,    60] loss: 0.649\n",
      "[20,    90] loss: 0.648\n",
      "[21,    30] loss: 0.646\n",
      "[21,    60] loss: 0.646\n",
      "[21,    90] loss: 0.648\n",
      "[22,    30] loss: 0.643\n",
      "[22,    60] loss: 0.647\n",
      "[22,    90] loss: 0.645\n",
      "[23,    30] loss: 0.642\n",
      "[23,    60] loss: 0.644\n",
      "[23,    90] loss: 0.643\n",
      "[24,    30] loss: 0.642\n",
      "[24,    60] loss: 0.642\n",
      "[24,    90] loss: 0.639\n",
      "[25,    30] loss: 0.640\n",
      "[25,    60] loss: 0.639\n",
      "[25,    90] loss: 0.640\n",
      "[26,    30] loss: 0.641\n",
      "[26,    60] loss: 0.635\n",
      "[26,    90] loss: 0.636\n",
      "[27,    30] loss: 0.640\n",
      "[27,    60] loss: 0.632\n",
      "[27,    90] loss: 0.637\n",
      "[28,    30] loss: 0.638\n",
      "[28,    60] loss: 0.634\n",
      "[28,    90] loss: 0.636\n",
      "[29,    30] loss: 0.631\n",
      "[29,    60] loss: 0.634\n",
      "[29,    90] loss: 0.632\n",
      "[30,    30] loss: 0.633\n",
      "[30,    60] loss: 0.631\n",
      "[30,    90] loss: 0.626\n",
      "[31,    30] loss: 0.632\n",
      "[31,    60] loss: 0.629\n",
      "[31,    90] loss: 0.627\n",
      "[32,    30] loss: 0.630\n",
      "[32,    60] loss: 0.626\n",
      "[32,    90] loss: 0.625\n",
      "[33,    30] loss: 0.624\n",
      "[33,    60] loss: 0.626\n",
      "[33,    90] loss: 0.625\n",
      "[34,    30] loss: 0.624\n",
      "[34,    60] loss: 0.628\n",
      "[34,    90] loss: 0.623\n",
      "[35,    30] loss: 0.623\n",
      "[35,    60] loss: 0.622\n",
      "[35,    90] loss: 0.625\n",
      "[36,    30] loss: 0.623\n",
      "[36,    60] loss: 0.622\n",
      "[36,    90] loss: 0.623\n",
      "[37,    30] loss: 0.620\n",
      "[37,    60] loss: 0.622\n",
      "[37,    90] loss: 0.624\n",
      "[38,    30] loss: 0.619\n",
      "[38,    60] loss: 0.623\n",
      "[38,    90] loss: 0.617\n",
      "[39,    30] loss: 0.617\n",
      "[39,    60] loss: 0.622\n",
      "[39,    90] loss: 0.617\n",
      "[40,    30] loss: 0.620\n",
      "[40,    60] loss: 0.617\n",
      "[40,    90] loss: 0.617\n",
      "[41,    30] loss: 0.617\n",
      "[41,    60] loss: 0.613\n",
      "[41,    90] loss: 0.618\n",
      "[42,    30] loss: 0.616\n",
      "[42,    60] loss: 0.609\n",
      "[42,    90] loss: 0.615\n",
      "[43,    30] loss: 0.614\n",
      "[43,    60] loss: 0.616\n",
      "[43,    90] loss: 0.612\n",
      "[44,    30] loss: 0.612\n",
      "[44,    60] loss: 0.612\n",
      "[44,    90] loss: 0.609\n",
      "[45,    30] loss: 0.612\n",
      "[45,    60] loss: 0.608\n",
      "[45,    90] loss: 0.615\n",
      "[46,    30] loss: 0.610\n",
      "[46,    60] loss: 0.609\n",
      "[46,    90] loss: 0.611\n",
      "[47,    30] loss: 0.609\n",
      "[47,    60] loss: 0.610\n",
      "[47,    90] loss: 0.607\n",
      "[48,    30] loss: 0.609\n",
      "[48,    60] loss: 0.605\n",
      "[48,    90] loss: 0.606\n",
      "[49,    30] loss: 0.605\n",
      "[49,    60] loss: 0.605\n",
      "[49,    90] loss: 0.612\n",
      "[50,    30] loss: 0.609\n",
      "[50,    60] loss: 0.603\n",
      "[50,    90] loss: 0.604\n",
      "[51,    30] loss: 0.604\n",
      "[51,    60] loss: 0.604\n",
      "[51,    90] loss: 0.602\n",
      "[52,    30] loss: 0.602\n",
      "[52,    60] loss: 0.606\n",
      "[52,    90] loss: 0.598\n",
      "[53,    30] loss: 0.603\n",
      "[53,    60] loss: 0.601\n",
      "[53,    90] loss: 0.601\n",
      "[54,    30] loss: 0.602\n",
      "[54,    60] loss: 0.598\n",
      "[54,    90] loss: 0.604\n",
      "[55,    30] loss: 0.599\n",
      "[55,    60] loss: 0.601\n",
      "[55,    90] loss: 0.600\n",
      "[56,    30] loss: 0.599\n",
      "[56,    60] loss: 0.601\n",
      "[56,    90] loss: 0.598\n",
      "[57,    30] loss: 0.604\n",
      "[57,    60] loss: 0.595\n",
      "[57,    90] loss: 0.596\n",
      "[58,    30] loss: 0.598\n",
      "[58,    60] loss: 0.598\n",
      "[58,    90] loss: 0.595\n",
      "[59,    30] loss: 0.596\n",
      "[59,    60] loss: 0.590\n",
      "[59,    90] loss: 0.600\n",
      "[60,    30] loss: 0.594\n",
      "[60,    60] loss: 0.593\n",
      "[60,    90] loss: 0.599\n",
      "[61,    30] loss: 0.593\n",
      "[61,    60] loss: 0.597\n",
      "[61,    90] loss: 0.592\n",
      "[62,    30] loss: 0.595\n",
      "[62,    60] loss: 0.596\n",
      "[62,    90] loss: 0.593\n",
      "[63,    30] loss: 0.587\n",
      "[63,    60] loss: 0.594\n",
      "[63,    90] loss: 0.594\n",
      "[64,    30] loss: 0.589\n",
      "[64,    60] loss: 0.594\n",
      "[64,    90] loss: 0.591\n",
      "[65,    30] loss: 0.591\n",
      "[65,    60] loss: 0.593\n",
      "[65,    90] loss: 0.587\n",
      "[66,    30] loss: 0.596\n",
      "[66,    60] loss: 0.586\n",
      "[66,    90] loss: 0.586\n",
      "[67,    30] loss: 0.588\n",
      "[67,    60] loss: 0.591\n",
      "[67,    90] loss: 0.586\n",
      "[68,    30] loss: 0.589\n",
      "[68,    60] loss: 0.587\n",
      "[68,    90] loss: 0.589\n",
      "[69,    30] loss: 0.591\n",
      "[69,    60] loss: 0.583\n",
      "[69,    90] loss: 0.588\n",
      "[70,    30] loss: 0.583\n",
      "[70,    60] loss: 0.586\n",
      "[70,    90] loss: 0.588\n",
      "[71,    30] loss: 0.583\n",
      "[71,    60] loss: 0.588\n",
      "[71,    90] loss: 0.586\n",
      "[72,    30] loss: 0.584\n",
      "[72,    60] loss: 0.588\n",
      "[72,    90] loss: 0.582\n",
      "[73,    30] loss: 0.585\n",
      "[73,    60] loss: 0.581\n",
      "[73,    90] loss: 0.587\n",
      "[74,    30] loss: 0.589\n",
      "[74,    60] loss: 0.580\n",
      "[74,    90] loss: 0.583\n",
      "[75,    30] loss: 0.580\n",
      "[75,    60] loss: 0.580\n",
      "[75,    90] loss: 0.587\n",
      "[76,    30] loss: 0.581\n",
      "[76,    60] loss: 0.579\n",
      "[76,    90] loss: 0.581\n",
      "[77,    30] loss: 0.575\n",
      "[77,    60] loss: 0.582\n",
      "[77,    90] loss: 0.586\n",
      "[78,    30] loss: 0.576\n",
      "[78,    60] loss: 0.581\n",
      "[78,    90] loss: 0.583\n",
      "[79,    30] loss: 0.579\n",
      "[79,    60] loss: 0.582\n",
      "[79,    90] loss: 0.577\n",
      "[80,    30] loss: 0.577\n",
      "[80,    60] loss: 0.575\n",
      "[80,    90] loss: 0.581\n",
      "[81,    30] loss: 0.577\n",
      "[81,    60] loss: 0.578\n",
      "[81,    90] loss: 0.575\n",
      "[82,    30] loss: 0.576\n",
      "[82,    60] loss: 0.576\n",
      "[82,    90] loss: 0.578\n",
      "[83,    30] loss: 0.579\n",
      "[83,    60] loss: 0.577\n",
      "[83,    90] loss: 0.572\n",
      "[84,    30] loss: 0.579\n",
      "[84,    60] loss: 0.570\n",
      "[84,    90] loss: 0.573\n",
      "[85,    30] loss: 0.577\n",
      "[85,    60] loss: 0.574\n",
      "[85,    90] loss: 0.575\n",
      "[86,    30] loss: 0.576\n",
      "[86,    60] loss: 0.577\n",
      "[86,    90] loss: 0.570\n",
      "[87,    30] loss: 0.578\n",
      "[87,    60] loss: 0.569\n",
      "[87,    90] loss: 0.574\n",
      "[88,    30] loss: 0.575\n",
      "[88,    60] loss: 0.576\n",
      "[88,    90] loss: 0.571\n",
      "[89,    30] loss: 0.575\n",
      "[89,    60] loss: 0.570\n",
      "[89,    90] loss: 0.568\n",
      "[90,    30] loss: 0.577\n",
      "[90,    60] loss: 0.565\n",
      "[90,    90] loss: 0.572\n",
      "[91,    30] loss: 0.571\n",
      "[91,    60] loss: 0.572\n",
      "[91,    90] loss: 0.570\n",
      "[92,    30] loss: 0.566\n",
      "[92,    60] loss: 0.571\n",
      "[92,    90] loss: 0.572\n",
      "[93,    30] loss: 0.570\n",
      "[93,    60] loss: 0.570\n",
      "[93,    90] loss: 0.572\n",
      "[94,    30] loss: 0.567\n",
      "[94,    60] loss: 0.571\n",
      "[94,    90] loss: 0.568\n",
      "[95,    30] loss: 0.569\n",
      "[95,    60] loss: 0.571\n",
      "[95,    90] loss: 0.567\n",
      "[96,    30] loss: 0.568\n",
      "[96,    60] loss: 0.568\n",
      "[96,    90] loss: 0.565\n",
      "[97,    30] loss: 0.568\n",
      "[97,    60] loss: 0.569\n",
      "[97,    90] loss: 0.566\n",
      "[98,    30] loss: 0.569\n",
      "[98,    60] loss: 0.559\n",
      "[98,    90] loss: 0.571\n",
      "[99,    30] loss: 0.568\n",
      "[99,    60] loss: 0.564\n",
      "[99,    90] loss: 0.565\n",
      "[100,    30] loss: 0.565\n",
      "[100,    60] loss: 0.566\n",
      "[100,    90] loss: 0.565\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "m = butterfly.deepinsight.deepinsight.DeepInsight(\n",
    "    input_dim=X_train_album.shape[2:],\n",
    "    kernel_size1=1, kernel_size2=2, n_initial_filters=1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(m.parameters(), lr=0.001, momentum=0.9, )\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader_train):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = m(inputs.reshape(-1, 1, *inputs.shape[1:]))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        every = 30\n",
    "        if i % every == every - 1:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8322822822822823"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = m(torch.tensor(X_train_album[:,[1],:,:]).float())\n",
    "y_pred = np.argmax(y_pred_proba.detach().numpy(), axis=1)\n",
    "sklearn.metrics.accuracy_score(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405405405405405"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = m(torch.tensor(X_test_album[:,[1],:,:]).float())\n",
    "y_pred = np.argmax(y_pred_proba.detach().numpy(), axis=1)\n",
    "sklearn.metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_raw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(rf.predict(X_train_raw), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581081081081081"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(rf.predict(X_test_raw), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (butterfly)",
   "language": "python",
   "name": "nalab-butterfly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
