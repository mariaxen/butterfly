{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# disable parallelization for BLAS and co.\n",
    "from nalabtools.utils.parallelization import set_threads_for_external_libraries\n",
    "set_threads_for_external_libraries(n_threads=1)\n",
    "\n",
    "# general\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ml / stats\n",
    "import sklearn\n",
    "import statsmodels.stats.multitest\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nalab\n",
    "import nalabtools\n",
    "\n",
    "# init notebook files\n",
    "import nalabtools.utils.misc\n",
    "nb = nalabtools.utils.misc.NotebookContext(\"martin_001_deepinsight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "file = h5py.File('../data/deepinsight/dataset2.mat', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_main_raw = file[\"dset\"][\"Xtrain\"][...]\n",
    "X_test_raw = file[\"dset\"][\"Xtest\"][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = np.repeat([0,1], file[\"dset\"][\"num_tr\"][...].flatten().astype(np.int))\n",
    "y_test = np.repeat([0,1], file[\"dset\"][\"num_tst\"][...].flatten().astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6660, 20) (6660,) (740, 20) (740,)\n"
     ]
    }
   ],
   "source": [
    "print(X_main_raw.shape, y_main.shape, X_test_raw.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = sklearn.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.05).split(X_main_raw, y_main)\n",
    "train_idx, val_idx = next(splits)\n",
    "X_train_raw = X_main_raw[train_idx, :]\n",
    "y_train = y_main[train_idx]\n",
    "X_val_raw = X_main_raw[val_idx, :]\n",
    "y_val = y_main[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = sklearn.preprocessing.MinMaxScaler().fit(X_train_raw)\n",
    "X_train = preprocessing.transform(X_train_raw)\n",
    "X_val = preprocessing.transform(X_val_raw)\n",
    "X_test = preprocessing.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive images and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import butterfly.deepinsight.album2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = butterfly.deepinsight.album2.AlbumTransformer(40)\n",
    "at.fit(X_train)\n",
    "X_train_album = at.transform_parallel(X_train, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_album = at.transform_parallel(X_val, n_jobs=None)\n",
    "X_test_album = at.transform_parallel(X_test, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "dataset_train = butterfly.deepinsight.album2.AlbumDataset(X_train_album[:,[1],:,:], y_train)\n",
    "dataset_val = butterfly.deepinsight.album2.AlbumDataset(X_val_album[:,[1],:,:], y_val)\n",
    "dataset_test = butterfly.deepinsight.album2.AlbumDataset(X_test_album[:,[1],:,:], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=bs, shuffle=True, num_workers=2)\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=bs * 2)\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import butterfly.deepinsight.deepinsight\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(nb.folder('runs/exp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grid = torchvision.utils.make_grid(torch.from_numpy(X_train_album[:4,[1],:,:]), padding=10)\n",
    "\n",
    "writer.add_image('test_image', img_grid)\n",
    "matplotlib_imshow(img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import butterfly.deepinsight.deepinsight\n",
    "m = butterfly.deepinsight.deepinsight.DeepInsight(\n",
    "    input_dim=X_train_album.shape[2:],\n",
    "    kernel_size1=1, kernel_size2=2, n_initial_filters=1)\n",
    "\n",
    "\n",
    "dataiter = iter(dataloader_train)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "writer.add_graph(m, images[:4,:])\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# # embeddings\n",
    "# # Bugfix: https://github.com/pytorch/pytorch/issues/30966\n",
    "# import tensorflow as tf\n",
    "# import tensorboard as tb\n",
    "# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "# features = images.view(-1, 40 * 40)\n",
    "# writer.add_embedding(features,\n",
    "#                     metadata=labels,\n",
    "#                     label_img=images.unsqueeze(1))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing [epoch=99, batch=89] training_loss=0.000: 100%|██████████| 100/100 [04:56<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(m.parameters(), lr=0.001, momentum=0.9, )\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "pbar = tqdm(range(100))\n",
    "for epoch in pbar:  # loop over the dataset multiple times\n",
    "\n",
    "    m.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader_train):\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = m(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        every = 30\n",
    "        if i % every == every - 1:\n",
    "            \n",
    "            m.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                loss_val = sum(criterion(m(x), y) for x, y in dataloader_val)\n",
    "                loss_val /= len(dataloader_val)\n",
    "                \n",
    "            loss_train = running_loss / every\n",
    "            writer.add_scalars(\"loss\", dict(train=loss_train, validation=loss_val), epoch * len(dataloader_train) + i)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            pbar.set_description(f\"Processing [epoch={epoch}, batch={i:2d}] training_loss={running_loss / every:.03f}\")\n",
    "            \n",
    "            m.train()\n",
    "        \n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- [x] visualize validation loss\n",
    "- [x] visualize images ... everyhting else in the tensorboard tutorial\n",
    "- [ ] get AFCS files and run the first single cell thingy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.960328749802434"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = m(torch.tensor(X_train_album[:,[1],:,:]).float())\n",
    "y_pred = np.argmax(y_pred_proba.detach().numpy(), axis=1)\n",
    "sklearn.metrics.accuracy_score(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9540540540540541"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = m(torch.tensor(X_test_album[:,[1],:,:]).float())\n",
    "y_pred = np.argmax(y_pred_proba.detach().numpy(), axis=1)\n",
    "sklearn.metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_raw, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(rf.predict(X_train_raw), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581081081081081"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(rf.predict(X_test_raw), y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (butterfly)",
   "language": "python",
   "name": "nalab-butterfly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
