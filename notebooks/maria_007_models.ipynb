{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import *    \n",
    "import os \n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import butterfly.album\n",
    "import butterfly.Models\n",
    "from itertools import combinations \n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from random import sample\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import random\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects.numpy2ri import numpy2ri\n",
    "import sys, getopt\n",
    "import re\n",
    "import tzlocal\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects import pandas2ri"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Model\n",
    "folds = 10 #number of folds\n",
    "features = 1 #number of features to predict\n",
    "epochs = 200 #number of epochs\n",
    "optimiser = 'adam' #model optimiser\n",
    "loss = 'mse' #model loss\n",
    "ntrees = 100\n",
    "kernel_size = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Import your data\n",
    "#DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Define the predictor datasets\n",
    "omics = ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/src/butterfly')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('albums_all.pkl', 'rb') as f:\n",
    "    albums_all = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('albums.pkl', 'rb') as f:\n",
    "    albums = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/notebooks')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('RF_predictor.pkl', 'rb') as f:\n",
    "    RF_predictor = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('groups_c.pkl', 'rb') as f:\n",
    "    groups_c = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('responses_50.pkl', 'rb') as f:\n",
    "    responses = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples = 50 #same as the number of responses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "utils = importr('utils')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "utils.install_packages('pcLasso')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "groups = DF['patientID']\n",
    "\n",
    "group_cols = groups_c[predictor_index]\n",
    "\n",
    "#Get your response dataset\n",
    "response = responses[predictor_index]\n",
    "response_df = DF[response]\n",
    "y = response_df.values\n",
    "\n",
    "yy = y.copy()\n",
    "\n",
    "y = QuantileTransformer().fit_transform(y)\n",
    "\n",
    "y = y[:,feat_n]\n",
    "\n",
    "X = RF_predictor[predictor_index]\n",
    "\n",
    "#############\n",
    "\n",
    "results = []\n",
    "\n",
    "y_prediction_train = []\n",
    "y_observed_train = []\n",
    "\n",
    "y_prediction_test = []\n",
    "y_observed_test = []\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=folds)\n",
    "\n",
    "y_pred_train_models = []\n",
    "y_pred_test_models = []\n",
    "\n",
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    yy_train, yy_test = yy[train_index], yy[test_index]\n",
    "    groups_train = groups[train_index]\n",
    "\n",
    "    #Model 1\n",
    "    RF = RandomForestRegressor(n_estimators=ntrees,\n",
    "                               min_samples_split = 5,\n",
    "                               random_state=0)\n",
    "    RF.fit(X_train, y_train)\n",
    "\n",
    "    #Model 2\n",
    "    Lasso = linear_model.Lasso(alpha=0.1)\n",
    "    Lasso.fit(X_train, y_train)\n",
    "\n",
    "    #Model 3\n",
    "    y_train_gl = y_train.reshape(-1, 1)\n",
    "\n",
    "    sparsegroupLasso = GroupLasso(\n",
    "        groups=group_cols,\n",
    "        group_reg=5,\n",
    "        l1_reg=0,\n",
    "        frobenius_lipschitz=True,\n",
    "        scale_reg=\"inverse_group_size\",\n",
    "        subsampling_scheme=1,\n",
    "        supress_warning=True,\n",
    "        n_iter=1000,\n",
    "        tol=1e-3,\n",
    "        )\n",
    "    sparsegroupLasso.fit(X_train, y_train_gl)\n",
    "\n",
    "    # demonstrate prediction        \n",
    "    y_pred_train_RF = pd.DataFrame(RF.predict(X_train))\n",
    "    y_pred_train_ls = pd.DataFrame(Lasso.predict(X_train))\n",
    "    y_pred_train_gl = pd.DataFrame(sparsegroupLasso.predict(X_train))\n",
    "\n",
    "    y_pred_train_models.append(y_pred_train_RF)\n",
    "    y_pred_train_models.append(y_pred_train_ls)\n",
    "    y_pred_train_models.append(y_pred_train_gl)\n",
    "\n",
    "    y_pred_test_RF = pd.DataFrame(RF.predict(X_test))\n",
    "    y_pred_test_ls = pd.DataFrame(Lasso.predict(X_test))\n",
    "    y_pred_test_gl = pd.DataFrame(sparsegroupLasso.predict(X_test))\n",
    "\n",
    "    y_pred_test_models.append(y_pred_test_RF)\n",
    "    y_pred_test_models.append(y_pred_test_ls)\n",
    "    y_pred_test_models.append(y_pred_test_gl)\n",
    "\n",
    "    y_pred_test_train_all = []\n",
    "    y_obsr_test_train = []\n",
    "\n",
    "    for train_train_index, test_train_index in group_kfold.split(X_train, y_train, groups_train):\n",
    "\n",
    "        X_train_train, X_test_train = X_train[train_train_index], X_train[test_train_index]\n",
    "        y_train_train, y_test_train = y_train[train_train_index], y_train[test_train_index]\n",
    "        yy_train_train, yy_test_train = yy_train[train_train_index], yy_train[test_train_index]\n",
    "\n",
    "        y_pred_test_train = []\n",
    "\n",
    "        #Model 1\n",
    "        RF = RandomForestRegressor(n_estimators=ntrees,\n",
    "                                   min_samples_split = 5,\n",
    "                                   random_state=0)\n",
    "        RF.fit(X_train_train, y_train_train)\n",
    "\n",
    "        #Model 2\n",
    "        Lasso = linear_model.Lasso(alpha=0.1)\n",
    "        Lasso.fit(X_train_train, y_train_train)\n",
    "\n",
    "        #Model 3\n",
    "        y_train_train_gl = y_train_train.reshape(-1, 1)\n",
    "\n",
    "        sparsegroupLasso = GroupLasso(\n",
    "            groups=group_cols,\n",
    "            group_reg=5,\n",
    "            l1_reg=0,\n",
    "            frobenius_lipschitz=True,\n",
    "            scale_reg=\"inverse_group_size\",\n",
    "            subsampling_scheme=1,\n",
    "            supress_warning=True,\n",
    "            n_iter=1000,\n",
    "            tol=1e-3,\n",
    "            )\n",
    "        sparsegroupLasso.fit(X_train_train, y_train_train_gl)\n",
    "\n",
    "        RF_pred = RF.predict(X_test_train)\n",
    "        LS_pred = Lasso.predict(X_test_train)\n",
    "        GL_pred = sparsegroupLasso.predict(X_test_train)\n",
    "\n",
    "        y_pred_test_train.append(RF_pred)        \n",
    "        y_pred_test_train.append(LS_pred)\n",
    "        y_pred_test_train.append(GL_pred)\n",
    "\n",
    "        y_pred_test_train_cv = pd.DataFrame(y_pred_test_train).transpose() \n",
    "        y_pred_test_train_all.append(y_pred_test_train_cv)\n",
    "        y_obsr_test_train.append(y_test_train)\n",
    "\n",
    "    y_pred_all_train = pd.concat(y_pred_test_train_all)\n",
    "    y_obsr_all_train = np.concatenate(y_obsr_test_train, axis=None)\n",
    "\n",
    "    if metaclassifier == \"non_negative\":\n",
    "\n",
    "        meta_model = linear_model.Lasso(alpha=0.1, positive = True)\n",
    "\n",
    "    meta_model.fit(y_pred_all_train, y_obsr_all_train)\n",
    "\n",
    "\n",
    "    y_pred_train = pd.DataFrame(y_pred_train_models).transpose() \n",
    "    X_tr = y_pred_train.values                \n",
    "\n",
    "    y_pred_test = pd.DataFrame(y_pred_test_models).transpose() \n",
    "    X_tst = y_pred_test.values                "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.Stacked_models)(DF, responses, predictor_index, \n",
    "                                                              feat_n, RF_predictor, folds, ntrees,\n",
    "                                                              \"matrix\", groups_c, \"non_negative\", False)\n",
    "                            for feat_n in range(n_samples)))\n",
    "        \n",
    "    RF['prediction_train'].append(prediction_train)\n",
    "    RF['observed_train'].append(observed_train)\n",
    "    RF['prediction_test'].append(prediction_test)\n",
    "    RF['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_50')\n",
    "with open('Stacked_models_NS.pkl', 'wb') as f:  \n",
    "    pickle.dump(RF, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.RLRF)(DF, responses, predictor_index, feat_n, \n",
    "                            RF_predictor, folds, ntrees, 'pcLasso', 'matrix', groups_c, True)for feat_n in list(range(20, 22))))\n",
    "        \n",
    "    RF['prediction_train'].append(prediction_train)\n",
    "    RF['observed_train'].append(observed_train)\n",
    "    RF['prediction_test'].append(prediction_test)\n",
    "    RF['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_50')\n",
    "with open('pcLasso_M_S_11.pkl', 'wb') as f:  \n",
    "    pickle.dump(RF, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.RLRF)(DF, responses, predictor_index, feat_n, \n",
    "                            RF_predictor, folds, ntrees, 'blockForest', 'matrix', groups_c, False)\n",
    "                            for feat_n in range(0, n_samples)))\n",
    "        \n",
    "    RF['prediction_train'].append(prediction_train)\n",
    "    RF['observed_train'].append(observed_train)\n",
    "    RF['prediction_test'].append(prediction_test)\n",
    "    RF['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_50')\n",
    "with open('BRF_M_NS.pkl', 'wb') as f:  \n",
    "    pickle.dump(RF, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "        \n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.RLRF)(DF, responses, predictor_index, feat_n, RF_predictor, \n",
    "                      folds, ntrees, \"pcLasso\", 'matrix', groups_c, True)\n",
    "                            for feat_n in range(n_samples)))\n",
    "        \n",
    "    DNN['prediction_train'].append(prediction_train)\n",
    "    DNN['observed_train'].append(observed_train)\n",
    "    DNN['prediction_test'].append(prediction_test)\n",
    "    DNN['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_20_new4')\n",
    "with open('DNN_M_NS.pkl', 'wb') as f:  \n",
    "    pickle.dump(DNN, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "        \n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.NN)(RF_predictor, DF, feat_n, predictor_index,  \n",
    "                            responses, 128, features, folds, epochs, optimiser, loss, \n",
    "                                                          'DNN', 'matrix_2', 2, False)\n",
    "                            for feat_n in range(n_samples)))\n",
    "        \n",
    "    DNN['prediction_train'].append(prediction_train)\n",
    "    DNN['observed_train'].append(observed_train)\n",
    "    DNN['prediction_test'].append(prediction_test)\n",
    "    DNN['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_20_new4')\n",
    "with open('DNN_M_NS.pkl', 'wb') as f:  \n",
    "    pickle.dump(DNN, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "        \n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.CNN)(RF_predictor, DF, feat_n, predictor_index,  \n",
    "                            responses, 128, features, folds, epochs, optimiser, loss, 'CNN', \n",
    "                                                          'matrix_3', 1)for feat_n in range(n_samples)))\n",
    "        \n",
    "    CNN['prediction_train'].append(prediction_train)\n",
    "    CNN['observed_train'].append(observed_train)\n",
    "    CNN['prediction_test'].append(prediction_test)\n",
    "    CNN['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_20_new3')\n",
    "with open('CNN_M_S2.pkl', 'wb') as f:  \n",
    "    pickle.dump(CNN, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MCNN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "        \n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.CNN)(albums, DF, feat_n, predictor_index,  \n",
    "                            responses, 40, features, folds, epochs, optimiser, loss, 'MCNN',\n",
    "                                                         'TSNE_M',2)for feat_n in range(n_samples)))\n",
    "        \n",
    "    MCNN['prediction_train'].append(prediction_train)\n",
    "    MCNN['observed_train'].append(observed_train)\n",
    "    MCNN['prediction_test'].append(prediction_test)\n",
    "    MCNN['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_20_new3')\n",
    "with open('MCNN_T_NS.pkl', 'wb') as f:  \n",
    "    pickle.dump(MCNN, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.LRF)(DF, responses, predictor_index, feat_n, \n",
    "                            RF_predictor, folds, ntrees, 'RF_regressor', 'matrix', groups_c, True)for feat_n in range(n_samples)))\n",
    "        \n",
    "    RF['prediction_train'].append(prediction_train)\n",
    "    RF['observed_train'].append(observed_train)\n",
    "    RF['prediction_test'].append(prediction_test)\n",
    "    RF['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_50')\n",
    "with open('RF_M_S.pkl', 'wb') as f:  \n",
    "    pickle.dump(RF, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LS = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.RF)(DF, responses, predictor_index, feat_n, \n",
    "                            RF_predictor, folds, ntrees, 'Lasso', 'matrix')for feat_n in range(n_samples)))\n",
    "        \n",
    "    LS['prediction_train'].append(prediction_train)\n",
    "    LS['observed_train'].append(observed_train)\n",
    "    LS['prediction_test'].append(prediction_test)\n",
    "    LS['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/data/pickles/models_20_new2')\n",
    "with open('LS_S.pkl', 'wb') as f:  \n",
    "    pickle.dump(LS, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dummy = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "\n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.RF)(DF, responses, predictor_index, feat_n, \n",
    "                            RF_predictor, folds, ntrees, 'Dummy')for feat_n in range(n_samples)))\n",
    "        \n",
    "    Dummy['prediction_train'].append(prediction_train)\n",
    "    Dummy['observed_train'].append(observed_train)\n",
    "    Dummy['prediction_test'].append(prediction_test)\n",
    "    Dummy['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('Dummy.pkl', 'wb') as f:  \n",
    "    pickle.dump(Dummy, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load model\n",
    "model = ResNet50()\n",
    "# summarize the model\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_samples = 30 #same as the number of responses\n",
    "\n",
    "RN = defaultdict(list)\n",
    "\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "        \n",
    "    prediction_train, observed_train, prediction_test, observed_test = zip(*Parallel(n_jobs=n_samples)\n",
    "                           (delayed(butterfly.Models.CNN)(albums_all, DF, feat_n, predictor_index,  \n",
    "                            responses, 128, features, folds, epochs, optimiser, loss, 'ResNet')for feat_n in range(n_samples)))\n",
    "        \n",
    "    RN['prediction_train'].append(prediction_train)\n",
    "    RN['observed_train'].append(observed_train)\n",
    "    RN['prediction_test'].append(prediction_test)\n",
    "    RN['observed_test'].append(observed_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('/home/mxenoc/workspace/butterfly/notebooks')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('MCNN_M.pkl', 'rb') as f:\n",
    "    MCNN_M = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('CNN_Matrix.pkl', 'rb') as f:\n",
    "    CNN_Matrix = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('CNN.pkl', 'rb') as f:\n",
    "    CNN = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('RF.pkl', 'rb') as f:\n",
    "    RF = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('MCNN.pkl', 'rb') as f:\n",
    "    MCNN = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('RF_T.pkl', 'rb') as f:\n",
    "    RF_T = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#responses\n",
    "feats  = np.hstack([np.tile('rna',n_samples), np.tile('plasma_l',n_samples), np.tile('serum_l',n_samples), np.tile('microbiome',n_samples), \n",
    "                    np.tile('immune',n_samples), np.tile('metabolomics',n_samples), np.tile('plasma_s',n_samples)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_CNN_r = []\n",
    "each_omic_CNN_p = []\n",
    "\n",
    "all_features_CNN_r = []\n",
    "all_features_CNN_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_CNN_r = []\n",
    "    each_feature_CNN_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_CNN_r.append(stats.spearmanr(CNN['prediction_test'][l][k], \n",
    "                                                          CNN['observed_test'][l][k])[0])\n",
    "            each_feature_CNN_p.append(stats.spearmanr(CNN['prediction_test'][l][k], \n",
    "                                                          CNN['observed_test'][l][k])[1])\n",
    "    all_features_CNN_r.append(each_feature_CNN_r)\n",
    "    all_features_CNN_p.append(each_feature_CNN_p)\n",
    "    each_omic_CNN_r.append(np.mean(each_feature_CNN_r))    \n",
    "    each_omic_CNN_p.append(np.mean(each_feature_CNN_p))    \n",
    "    \n",
    "CNN_r = np.hstack(all_features_CNN_r)\n",
    "CNN_p = np.hstack(all_features_CNN_p)\n",
    "CNN_r_p = pd.DataFrame({'r': CNN_r, 'p': CNN_p, 'omics': feats, 'model': 'CNN'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNN_r_p = pd.DataFrame({'r': CNN_r, 'p': CNN_p, 'omics': feats, 'model': 'CNN'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_LS_r = []\n",
    "each_omic_LS_p = []\n",
    "\n",
    "all_features_LS_r = []\n",
    "all_features_LS_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_LS_r = []\n",
    "    each_feature_LS_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_LS_r.append(stats.spearmanr(LS['prediction_test'][l][k], \n",
    "                                                          LS['observed_test'][l][k])[0])\n",
    "            each_feature_LS_p.append(stats.spearmanr(LS['prediction_test'][l][k], \n",
    "                                                          LS['observed_test'][l][k])[1])\n",
    "    all_features_LS_r.append(each_feature_LS_r)\n",
    "    all_features_LS_p.append(each_feature_LS_p)\n",
    "    each_omic_LS_r.append(np.mean(each_feature_LS_r))    \n",
    "    each_omic_LS_p.append(np.mean(each_feature_LS_p))    \n",
    "    \n",
    "LS_r = np.hstack(all_features_LS_r)\n",
    "LS_p = np.hstack(all_features_LS_p)\n",
    "LS_r_p = pd.DataFrame({'r': LS_r, 'p': LS_p, 'omics': feats, 'model': 'LS'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LS_r_p = pd.DataFrame({'r': LS_r, 'p': LS_p, 'omics': feats, 'model': 'LS'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_r = []\n",
    "each_omic_p = []\n",
    "\n",
    "all_features_r = []\n",
    "all_features_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_r = []\n",
    "    each_feature_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_r.append(stats.spearmanr(MCNN_M['prediction_test'][l][k], \n",
    "                                                          MCNN_M['observed_test'][l][k])[0])\n",
    "            each_feature_p.append(stats.spearmanr(MCNN_M['prediction_test'][l][k], \n",
    "                                                          MCNN_M['observed_test'][l][k])[1])\n",
    "    all_features_r.append(each_feature_r)\n",
    "    all_features_p.append(each_feature_p)\n",
    "    each_omic_r.append(np.mean(each_feature_r))    \n",
    "    each_omic_p.append(np.mean(each_feature_p))  \n",
    "    \n",
    "r = np.hstack(all_features_r)\n",
    "p = np.hstack(all_features_p)\n",
    "MCNN_M_r_p = pd.DataFrame({'r': r, 'p': p, 'omics': feats, 'model': 'CNN_Matrix'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_RF_r = []\n",
    "each_omic_RF_p = []\n",
    "\n",
    "all_features_RF_r = []\n",
    "all_features_RF_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_RF_r = []\n",
    "    each_feature_RF_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_RF_r.append(stats.spearmanr(RF['prediction_test'][l][k], \n",
    "                                                          RF['observed_test'][l][k])[0])\n",
    "            each_feature_RF_p.append(stats.spearmanr(RF['prediction_test'][l][k], \n",
    "                                                          RF['observed_test'][l][k])[1])\n",
    "    all_features_RF_r.append(each_feature_RF_r)\n",
    "    all_features_RF_p.append(each_feature_RF_p)\n",
    "    each_omic_RF_r.append(np.mean(each_feature_RF_r))    \n",
    "    each_omic_RF_p.append(np.mean(each_feature_RF_p))    \n",
    "    \n",
    "RF_r = np.hstack(all_features_RF_r)\n",
    "RF_p = np.hstack(all_features_RF_p)\n",
    "RF_r_p = pd.DataFrame({'r': RF_r, 'p': RF_p, 'omics': feats, 'model': 'RF'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF_r_p = pd.DataFrame({'r': RF_r, 'p': RF_p, 'omics': feats, 'model': 'RF'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_MCNN_r = []\n",
    "each_omic_MCNN_p = []\n",
    "\n",
    "all_features_MCNN_r = []\n",
    "all_features_MCNN_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_MCNN_r = []\n",
    "    each_feature_MCNN_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_MCNN_r.append(stats.spearmanr(MCNN['prediction_test'][l][k], \n",
    "                                                          MCNN['observed_test'][l][k])[0])\n",
    "            each_feature_MCNN_p.append(stats.spearmanr(MCNN['prediction_test'][l][k], \n",
    "                                                          MCNN['observed_test'][l][k])[1])\n",
    "    all_features_MCNN_r.append(each_feature_MCNN_r)\n",
    "    all_features_MCNN_p.append(each_feature_MCNN_p)\n",
    "    each_omic_MCNN_r.append(np.mean(each_feature_MCNN_r))    \n",
    "    each_omic_MCNN_p.append(np.mean(each_feature_MCNN_p))    \n",
    "    \n",
    "MCNN_r = np.hstack(all_features_MCNN_r)\n",
    "MCNN_p = np.hstack(all_features_MCNN_p)\n",
    "MCNN_r_p = pd.DataFrame({'r': MCNN_r, 'p': MCNN_p, 'omics': feats, 'model': 'MCNN'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MCNN_r_p = pd.DataFrame({'r': MCNN_r, 'p': MCNN_p, 'omics': feats, 'model': 'MCNN'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_Dummy_r = []\n",
    "each_omic_Dummy_p = []\n",
    "\n",
    "all_features_Dummy_r = []\n",
    "all_features_Dummy_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_Dummy_r = []\n",
    "    each_feature_Dummy_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_Dummy_r.append(stats.spearmanr(Dummy['prediction_test'][l][k], \n",
    "                                                          Dummy['observed_test'][l][k])[0])\n",
    "            each_feature_Dummy_p.append(stats.spearmanr(Dummy['prediction_test'][l][k], \n",
    "                                                          Dummy['observed_test'][l][k])[1])\n",
    "    all_features_Dummy_r.append(each_feature_Dummy_r)\n",
    "    all_features_Dummy_p.append(each_feature_Dummy_p)\n",
    "    each_omic_Dummy_r.append(np.mean(each_feature_Dummy_r))    \n",
    "    each_omic_Dummy_p.append(np.mean(each_feature_Dummy_p))    \n",
    "    \n",
    "Dummy_r = np.hstack(all_features_Dummy_r)\n",
    "Dummy_p = np.hstack(all_features_Dummy_p)\n",
    "Dummy_r_p = pd.DataFrame({'r': Dummy_r, 'p': Dummy_p, 'omics': feats, 'model': 'Dummy'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dummy_r_p = pd.DataFrame({'r': Dummy_r, 'p': Dummy_p, 'omics': feats, 'model': 'Dummy'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "each_omic_Random_r = []\n",
    "each_omic_Random_p = []\n",
    "\n",
    "all_features_Random_r = []\n",
    "all_features_Random_p = []\n",
    "\n",
    "for l in range(len(omics)):\n",
    "    each_feature_Random_r = []\n",
    "    each_feature_Random_p = []\n",
    "    for k in range(n_samples):\n",
    "            each_feature_Random_r.append(stats.spearmanr(pd.DataFrame(random.sample(range(10, 100), 68)), \n",
    "                                                          RF['observed_test'][l][k])[0])\n",
    "            each_feature_Random_p.append(stats.spearmanr(pd.DataFrame(random.sample(range(10, 100), 68)), \n",
    "                                                          RF['observed_test'][l][k])[1])\n",
    "    all_features_Random_r.append(each_feature_Random_r)\n",
    "    all_features_Random_p.append(each_feature_Random_p)\n",
    "    each_omic_Random_r.append(np.mean(each_feature_Random_r))    \n",
    "    each_omic_Random_p.append(np.mean(each_feature_Random_p))    \n",
    "    \n",
    "Random_r = np.hstack(all_features_Random_r)\n",
    "Random_p = np.hstack(all_features_Random_p)\n",
    "Random_r_p = pd.DataFrame({'r': Random_r, 'p': Random_p, 'omics': feats, 'model': 'Random'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Random_r_p = pd.DataFrame({'r': Random_r, 'p': Random_p, 'omics': feats, 'model': 'Random'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Random_df = Random_r_p[(Random_r_p['r']>0) & (Random_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dummy_df = Dummy_r_p[(Dummy_r_p['r']>0) & (Dummy_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNN_Matrix_df = CNN_Matrix_r_p[(CNN_Matrix_r_p['r']>0) & (CNN_Matrix_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MCNN_df = MCNN_r_p[(MCNN_r_p['r']>0) & (MCNN_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF_T_df = RF_T_r_p[(RF_T_r_p['r']>0) & (RF_T_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RF_df = RF_r_p[(RF_r_p['r']>0) & (RF_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LS_df = LS_r_p[(LS_r_p['r']>0) & (LS_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CNN_df = CNN_r_p[(CNN_r_p['r']>0) & (CNN_r_p['p']<=0.05)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_frames = [RF_df, RF_T_df, LS_df, CNN_df, CNN_Matrix_df, MCNN_df, Random_df]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = pd.concat(df_frames, sort=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = dfs.iloc[:,0:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = dfs.groupby([\"omics\", \"model\"]).size().reset_index(name=\"Time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pivot_df = dfs.pivot(index='model', columns='omics', values='Time')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pivot_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('pivot_df_60.pkl', 'wb') as f:  \n",
    "    pickle.dump(pivot_df, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = [\"pink\", \"bisque\",\"olive\",\"skyblue\",\"goldenrod\",\"thistle\",\"gray\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictors = ['CNN_T', 'CNN_M', 'LASSO_M', 'MCNN_T', 'RF_M', 'RF_T', 'Random']\n",
    "y_pos = np.arange(len(predictors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pivot_df.plot.bar(stacked=True, color=colors, figsize=(13,10))\n",
    "plt.xticks(y_pos, predictors, rotation=0, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "#plt.xlabel('Models', fontsize=18)\n",
    "plt.legend(loc=2, prop={'size': 16})\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Number of features predicted', fontsize=20)\n",
    "plt.title('Prediction for 60 features from each dataset', fontsize=20)\n",
    "plt.savefig('benchmark.png', dpi=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictors = ['RF', 'LASSO', 'CNN', 'MCNN', 'Random', 'Dummy']\n",
    "y_pos = np.arange(len(predictors))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = [RF_df.shape[0], LS_df.shape[0], CNN_df.shape[0], \n",
    "            MCNN_df.shape[0], Random_df.shape[0], Dummy_df.shape[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plot the results\n",
    "f = plt.figure()\n",
    "plt.bar(y_pos, features, color=['firebrick', 'gold', 'olivedrab', 'royalblue', \n",
    "                                       'cyan', 'salmon'])\n",
    "plt.xticks(y_pos, predictors)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Number of features predicted')\n",
    "plt.title('Prediction for 20 features from each dataset')\n",
    "plt.xticks(rotation=0)\n",
    "#plt.show()\n",
    "\n",
    "#os.chdir(Desktop)\n",
    "f.savefig(\"Bars.pdf\", bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Boxplots\n",
    "bxp = sns.boxplot(x=predictors, y=features, palette=\"Set2\")\n",
    "bxp.set_xticklabels(bxp.get_xticklabels(),rotation=0)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Spearman r')\n",
    "plt.title('Accuracy over 20 features per omic dataset')\n",
    "#plt.show()\n",
    "fig = bxp.get_figure()\n",
    "fig.savefig(\"boxesFeat_serum_l_test.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}