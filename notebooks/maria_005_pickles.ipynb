{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mxenoc/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import butterfly.album\n",
    "import butterfly.Models\n",
    "from itertools import combinations \n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from random import sample\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the predictor datasets\n",
    "omics = ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import your data\n",
    "#DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [49:46<4:58:37, 2986.30s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "pixels = 128 #image size\n",
    "perplexity = 75 #perplexity for the tsne\n",
    "scaler = \"Standard\"\n",
    "\n",
    "albums_all_75 = []\n",
    "for predictor_index in tqdm(range(len(omics))):\n",
    "    \n",
    "    #Get your predictor dataset\n",
    "    predictors = list(omics)\n",
    "    predictors.remove(omics[predictor_index])\n",
    "    predictors = tuple(predictors)\n",
    "\n",
    "    albums_all_75.append(butterfly.album.create_album(\n",
    "        DF, predictors, pixels, perplexity, scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums_all_75.pkl', 'wb') as f:  \n",
    "    pickle.dump(albums_all_75, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_predictor = []\n",
    "for predictor_index in range(len(omics)):\n",
    "    \n",
    "    #Get your predictor dataset\n",
    "    DFB = DF.copy()\n",
    "\n",
    "    unwanted = DFB.columns[DFB.columns.str.startswith(omics[predictor_index])]\n",
    "    DFB.drop(unwanted, axis=1, inplace=True)\n",
    "    DFB.drop(['patient_TR', 'patientID', 'trimester'], axis=1, inplace=True)\n",
    "\n",
    "    RF_predictor.append(DFB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RF_predictor.pkl', 'wb') as f:  \n",
    "    pickle.dump(RF_predictor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 31.98it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "pixels = 40 #image size\n",
    "perplexity = 25 #perplexity for the tsne\n",
    "\n",
    "albums = Parallel(n_jobs=len(omics))(delayed(butterfly.album.create_album)\n",
    "                                                    (DF, omics[al], pixels, perplexity)\n",
    "                                                    for al in tqdm(range(len(omics))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('albums.pkl', 'wb') as f:  \n",
    "    pickle.dump(albums, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 30 #features to sample from each dataset\n",
    "\n",
    "#Define the predictor datasets\n",
    "omics = ['rna', 'plasma_l', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']\n",
    "\n",
    "#Import your data\n",
    "#DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]\n",
    "\n",
    "responses = []\n",
    "for predictor_index in range(len(omics)):\n",
    "    \n",
    "    #Get your response dataset\n",
    "    DFB = DF.copy()\n",
    "    response = sample([col for col in DFB if col.startswith(omics[predictor_index])], n_samples)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('responses_30.pkl', 'wb') as f:  \n",
    "    pickle.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = albums_all_50[4][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_im = plt.imshow(pic, cmap = 'RdGy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
