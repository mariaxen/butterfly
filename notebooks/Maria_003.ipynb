{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import *    \n",
    "import os \n",
    "import pyreadr\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pyreadr.read_r('/Users/mxenoc/Desktop/workspace/butterfly/data/omics.RData')\n",
    "#DF = pyreadr.read_r('/home/mxenoc/workspace/butterfly/data/omics.RData')\n",
    "DF = DF[\"DF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import butterfly.album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import butterfly.CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your responses, size, for the image and number of features we are predicting\n",
    "response = 'plasma_l'\n",
    "pixels = 40\n",
    "features = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide which dataset you want to predict\n",
    "response = [col for col in DF if col.startswith(response)]\n",
    "response.append(\"patientID\")\n",
    "response.append(\"trimester\")    \n",
    "response_df = DF[response]\n",
    "#Make sure your B trimesters are properly converted to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get every combination of patient IDs in pairs of m's\n",
    "# Function which returns subset or r length from n \n",
    "from itertools import combinations \n",
    "\n",
    "m = 2\n",
    "IDs = response_df['patientID'].unique()\n",
    "IDs = IDs.tolist()\n",
    "exclude = list(combinations(IDs, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['rna', 'serum_l', 'microb', 'immune', 'metabol', 'plasma_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor1 = predictors[0]\n",
    "predictor2 = predictors[1]\n",
    "predictor3 = predictors[2]\n",
    "predictor4 = predictors[3]\n",
    "predictor5 = predictors[4]\n",
    "predictor6 = predictors[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "album1 = butterfly.album.create_album(DF, predictor1, pixels)\n",
    "album2 = butterfly.album.create_album(DF, predictor2, pixels)\n",
    "album3 = butterfly.album.create_album(DF, predictor3, pixels)\n",
    "album4 = butterfly.album.create_album(DF, predictor4, pixels)\n",
    "album5 = butterfly.album.create_album(DF, predictor5, pixels)\n",
    "album6 = butterfly.album.create_album(DF, predictor6, pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = response_df.drop(['patientID', 'trimester'], axis =1 ).values\n",
    "prediction = []\n",
    "observed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(len(exclude)):\n",
    "    #Create your calibration and validation datasets\n",
    "    pt1ex = response_df.index[response_df['patientID'] == exclude[cv][0]].tolist()\n",
    "    pt2ex = response_df.index[response_df['patientID'] == exclude[cv][1]].tolist()\n",
    "    ptex = pt1ex+pt2ex\n",
    "\n",
    "    #Divide in calibration and validation\n",
    "    X_c1 = np.delete(album1, ptex, 0)\n",
    "    X_c1 = X_c1.reshape((X_c1.shape[0], X_c1.shape[1], pixels))\n",
    "    \n",
    "    X_c2 = np.delete(album2, ptex, 0)\n",
    "    X_c2 = X_c2.reshape((X_c2.shape[0], X_c2.shape[1], pixels))\n",
    "\n",
    "    X_c3 = np.delete(album3, ptex, 0)\n",
    "    X_c3 = X_c3.reshape((X_c3.shape[0], X_c3.shape[1], pixels))\n",
    "\n",
    "    X_c4 = np.delete(album4, ptex, 0)\n",
    "    X_c4 = X_c4.reshape((X_c4.shape[0], X_c4.shape[1], pixels))\n",
    "\n",
    "    X_c5 = np.delete(album5, ptex, 0)\n",
    "    X_c5 = X_c5.reshape((X_c5.shape[0], X_c5.shape[1], pixels))\n",
    "\n",
    "    X_c6 = np.delete(album6, ptex, 0)\n",
    "    X_c6 = X_c6.reshape((X_c6.shape[0], X_c6.shape[1], pixels))\n",
    "    \n",
    "    y_c = np.delete(yy, ptex, 0)\n",
    "    y_c = pd.DataFrame(StandardScaler().fit_transform(y_c))\n",
    "    \n",
    "    X_c = []\n",
    "\n",
    "    for i in range(60):\n",
    "        X_c.append(np.array((X_c1[i], X_c2[i], X_c3[i], X_c4[i], X_c5[i], X_c6[i]), dtype=float))\n",
    "    \n",
    "    X_c = np.array(X_c)\n",
    "    X_c = X_c.reshape((X_c.shape[0], pixels, pixels, X_c.shape[1]))\n",
    "\n",
    "    X_v1 = np.asarray([album1[i]  for i in ptex])\n",
    "    X_v1 = X_v1.reshape((X_v1.shape[0], X_v1.shape[1], pixels))\n",
    "\n",
    "    X_v2 = np.asarray([album2[i]  for i in ptex])\n",
    "    X_v2 = X_v2.reshape((X_v2.shape[0], X_v2.shape[1], pixels))\n",
    "\n",
    "    X_v3 = np.asarray([album3[i]  for i in ptex])\n",
    "    X_v3 = X_v3.reshape((X_v3.shape[0], X_v3.shape[1], pixels))\n",
    "\n",
    "    X_v4 = np.asarray([album4[i]  for i in ptex])\n",
    "    X_v4 = X_v4.reshape((X_v4.shape[0], X_v4.shape[1], pixels))\n",
    "\n",
    "    X_v5 = np.asarray([album5[i]  for i in ptex])\n",
    "    X_v5 = X_v5.reshape((X_v5.shape[0], X_v5.shape[1], pixels))\n",
    "\n",
    "    X_v6 = np.asarray([album6[i]  for i in ptex])\n",
    "    X_v6 = X_v6.reshape((X_v6.shape[0], X_v6.shape[1], pixels))    \n",
    "    \n",
    "    y_v = np.asarray([yy[i] for i in ptex])\n",
    "    y_v = pd.DataFrame(StandardScaler().fit_transform(y_v))\n",
    "    \n",
    "    X_v = []\n",
    "\n",
    "    for i in range(8):\n",
    "        X_v.append(np.array((X_v1[i], X_v2[i], X_v3[i], X_v4[i], X_v5[i], X_v6[i]), dtype=float))\n",
    "    \n",
    "    X_v = np.array(X_v)\n",
    "    X_v = X_v.reshape((X_v.shape[0], pixels, pixels, X_v.shape[1]))\n",
    "\n",
    "    #Create your CNN\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(3,3), input_shape=(pixels, pixels,6)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(features))\n",
    "    model.add(Activation( 'sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_c, y_c, epochs=300, verbose=0)\n",
    "\n",
    "    # demonstrate prediction\n",
    "    y_pred = model.predict(X_v, verbose = 0)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    prediction.append(y_pred)\n",
    "    observed.append(y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing\n",
    "\n",
    "#num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "#results = Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.concat(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.concat(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl = pred.corrwith(obs, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correl = bars_p[number].corrwith(bars_o[number], axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.402697\n",
       "1     0.427385\n",
       "2     0.367852\n",
       "3     0.389154\n",
       "4     0.409281\n",
       "        ...   \n",
       "57    0.387163\n",
       "58    0.363417\n",
       "59    0.425253\n",
       "60    0.442869\n",
       "61    0.235089\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl[correl < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5154415273036915"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(correl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23508928964231607"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(correl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.402697\n",
       "1     0.427385\n",
       "2     0.367852\n",
       "3     0.389154\n",
       "4     0.409281\n",
       "        ...   \n",
       "57    0.387163\n",
       "58    0.363417\n",
       "59    0.425253\n",
       "60    0.442869\n",
       "61    0.235089\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37873824750989293"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(correl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}